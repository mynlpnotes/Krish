# Tokenization and Basic Techniques

**Corpus:** Paragraph

**Documents:** Sentences

**Vocabulary:** Unique words present in the paragraph

**Words:** All the words present in the corpus



**Tokenization:**

* Lets say we have a paragraph - 'My name is Hitesh and I have a interest in learning ML, NLP and DL. And I am also working'
* This will be out corpus
* In tokenization we take paragraph or sentences and convert it into tokens
* Tokenization (Paragraph to sentences)  - It will split at fullstop or exclamation&#x20;
* \['My name is Hitesh and I have a interest in learning ML, NLP and DL' , 'And I am also working']
* Tokenization (Sentences to words)
* \['My', 'name', 'is'.......]
* Example: i like to drink apple juice. My friend like mango juice
* Tokenization: \['I like to drink apple juice', 'My friend like mango juice']
* Words = 11
* Unique words = 9
*
*
