# Word Embeddings

* In NLP, word embedding is a term used for the representation of words for text analysis, typically in the form of real value vector that encodes the meaning of the word such that the vector closer in the vector space are expected to be similar in the meaning
*

    <figure><img src="../../.gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>
