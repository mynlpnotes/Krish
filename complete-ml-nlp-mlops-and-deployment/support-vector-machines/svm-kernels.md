# SVM Kernels

* Here for classification, we have to fit the best fit line along with marginal plane, this is known as linear SVC
* But of we have data points which are not linearly separable and if we use linear SVC then accuracy will be low
* To solve such scenarios, we use SVM kernels
* Using kernel we will be applying some mathematical transformation
* This will create data in some other dimension, and now rit will be linearly separable
* And we can use linear SVC&#x20;
*   &#x20;

    <figure><img src="../../.gitbook/assets/image (24) (1).png" alt=""><figcaption></figcaption></figure>


* We can use linear SVC here
* Suppose we apply a transformation y = x2 and then we will be able to use linear SVC
*

    <figure><img src="../../.gitbook/assets/image (25) (1).png" alt=""><figcaption></figcaption></figure>
* Polynomial Kernel
* RBF kernel
* Sigmoid kernel
